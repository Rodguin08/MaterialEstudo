{"ast":null,"code":"var fs = require('fs');\n\nvar path = require('path');\n\nvar glob = require('glob');\n\nvar normalizeData = require('normalize-package-data');\n\nvar safeJSON = require('json-parse-even-better-errors');\n\nvar util = require('util');\n\nvar normalizePackageBin = require('npm-normalize-package-bin');\n\nmodule.exports = readJson; // put more stuff on here to customize.\n\nreadJson.extraSet = [bundleDependencies, gypfile, serverjs, scriptpath, authors, readme, mans, bins, githead, fillTypes];\nvar typoWarned = {};\nvar cache = {};\n\nfunction readJson(file, log_, strict_, cb_) {\n  var log, strict, cb;\n\n  for (var i = 1; i < arguments.length - 1; i++) {\n    if (typeof arguments[i] === 'boolean') {\n      strict = arguments[i];\n    } else if (typeof arguments[i] === 'function') {\n      log = arguments[i];\n    }\n  }\n\n  if (!log) {\n    log = function () {};\n  }\n\n  cb = arguments[arguments.length - 1];\n  readJson_(file, log, strict, cb);\n}\n\nfunction readJson_(file, log, strict, cb) {\n  fs.readFile(file, 'utf8', function (er, d) {\n    parseJson(file, er, d, log, strict, cb);\n  });\n}\n\nfunction stripBOM(content) {\n  // Remove byte order marker. This catches EF BB BF (the UTF-8 BOM)\n  // because the buffer-to-string conversion in `fs.readFileSync()`\n  // translates it to FEFF, the UTF-16 BOM.\n  if (content.charCodeAt(0) === 0xFEFF) {\n    content = content.slice(1);\n  }\n\n  return content;\n}\n\nfunction jsonClone(obj) {\n  if (obj == null) {\n    return obj;\n  } else if (Array.isArray(obj)) {\n    var newarr = new Array(obj.length);\n\n    for (var ii in obj) {\n      newarr[ii] = obj[ii];\n    }\n  } else if (typeof obj === 'object') {\n    var newobj = {};\n\n    for (var kk in obj) {\n      newobj[kk] = jsonClone[kk];\n    }\n  } else {\n    return obj;\n  }\n}\n\nfunction parseJson(file, er, d, log, strict, cb) {\n  if (er && er.code === 'ENOENT') {\n    return fs.stat(path.dirname(file), function (err, stat) {\n      if (!err && stat && !stat.isDirectory()) {\n        // ENOTDIR isn't used on Windows, but npm expects it.\n        er = Object.create(er);\n        er.code = 'ENOTDIR';\n        return cb(er);\n      } else {\n        return indexjs(file, er, log, strict, cb);\n      }\n    });\n  }\n\n  if (er) {\n    return cb(er);\n  }\n\n  if (cache[d]) {\n    return cb(null, jsonClone(cache[d]));\n  }\n\n  var data;\n\n  try {\n    data = safeJSON(stripBOM(d));\n\n    for (var key in data) {\n      if (/^_/.test(key)) {\n        delete data[key];\n      }\n    }\n  } catch (jsonErr) {\n    data = parseIndex(d);\n\n    if (!data) {\n      return cb(parseError(jsonErr, file));\n    }\n  }\n\n  extrasCached(file, d, data, log, strict, cb);\n}\n\nfunction extrasCached(file, d, data, log, strict, cb) {\n  extras(file, data, log, strict, function (err, extrasData) {\n    if (!err) {\n      cache[d] = jsonClone(extrasData);\n    }\n\n    cb(err, extrasData);\n  });\n}\n\nfunction indexjs(file, er, log, strict, cb) {\n  if (path.basename(file) === 'index.js') {\n    return cb(er);\n  }\n\n  var index = path.resolve(path.dirname(file), 'index.js');\n  fs.readFile(index, 'utf8', function (er2, d) {\n    if (er2) {\n      return cb(er);\n    }\n\n    if (cache[d]) {\n      return cb(null, cache[d]);\n    }\n\n    var data = parseIndex(d);\n\n    if (!data) {\n      return cb(er);\n    }\n\n    extrasCached(file, d, data, log, strict, cb);\n  });\n}\n\nreadJson.extras = extras;\n\nfunction extras(file, data, log_, strict_, cb_) {\n  var log, strict, cb;\n\n  for (var i = 2; i < arguments.length - 1; i++) {\n    if (typeof arguments[i] === 'boolean') {\n      strict = arguments[i];\n    } else if (typeof arguments[i] === 'function') {\n      log = arguments[i];\n    }\n  }\n\n  if (!log) {\n    log = function () {};\n  }\n\n  cb = arguments[i];\n  var set = readJson.extraSet;\n  var n = set.length;\n  var errState = null;\n  set.forEach(function (fn) {\n    fn(file, data, then);\n  });\n\n  function then(er) {\n    if (errState) {\n      return;\n    }\n\n    if (er) {\n      return cb(errState = er);\n    }\n\n    if (--n > 0) {\n      return;\n    }\n\n    final(file, data, log, strict, cb);\n  }\n}\n\nfunction scriptpath(file, data, cb) {\n  if (!data.scripts) {\n    return cb(null, data);\n  }\n\n  var k = Object.keys(data.scripts);\n  k.forEach(scriptpath_, data.scripts);\n  cb(null, data);\n}\n\nfunction scriptpath_(key) {\n  var s = this[key]; // This is never allowed, and only causes problems\n\n  if (typeof s !== 'string') {\n    return delete this[key];\n  }\n\n  var spre = /^(\\.[/\\\\])?node_modules[/\\\\].bin[\\\\/]/;\n\n  if (s.match(spre)) {\n    this[key] = this[key].replace(spre, '');\n  }\n}\n\nfunction gypfile(file, data, cb) {\n  var dir = path.dirname(file);\n  var s = data.scripts || {};\n\n  if (s.install || s.preinstall) {\n    return cb(null, data);\n  }\n\n  glob('*.gyp', {\n    cwd: dir\n  }, function (er, files) {\n    if (er) {\n      return cb(er);\n    }\n\n    if (data.gypfile === false) {\n      return cb(null, data);\n    }\n\n    gypfile_(file, data, files, cb);\n  });\n}\n\nfunction gypfile_(file, data, files, cb) {\n  if (!files.length) {\n    return cb(null, data);\n  }\n\n  var s = data.scripts || {};\n  s.install = 'node-gyp rebuild';\n  data.scripts = s;\n  data.gypfile = true;\n  return cb(null, data);\n}\n\nfunction serverjs(file, data, cb) {\n  var dir = path.dirname(file);\n  var s = data.scripts || {};\n\n  if (s.start) {\n    return cb(null, data);\n  }\n\n  glob('server.js', {\n    cwd: dir\n  }, function (er, files) {\n    if (er) {\n      return cb(er);\n    }\n\n    serverjs_(file, data, files, cb);\n  });\n}\n\nfunction serverjs_(file, data, files, cb) {\n  if (!files.length) {\n    return cb(null, data);\n  }\n\n  var s = data.scripts || {};\n  s.start = 'node server.js';\n  data.scripts = s;\n  return cb(null, data);\n}\n\nfunction authors(file, data, cb) {\n  if (data.contributors) {\n    return cb(null, data);\n  }\n\n  var af = path.resolve(path.dirname(file), 'AUTHORS');\n  fs.readFile(af, 'utf8', function (er, ad) {\n    // ignore error.  just checking it.\n    if (er) {\n      return cb(null, data);\n    }\n\n    authors_(file, data, ad, cb);\n  });\n}\n\nfunction authors_(file, data, ad, cb) {\n  ad = ad.split(/\\r?\\n/g).map(function (line) {\n    return line.replace(/^\\s*#.*$/, '').trim();\n  }).filter(function (line) {\n    return line;\n  });\n  data.contributors = ad;\n  return cb(null, data);\n}\n\nfunction readme(file, data, cb) {\n  if (data.readme) {\n    return cb(null, data);\n  }\n\n  var dir = path.dirname(file);\n  var globOpts = {\n    cwd: dir,\n    nocase: true,\n    mark: true\n  };\n  glob('{README,README.*}', globOpts, function (er, files) {\n    if (er) {\n      return cb(er);\n    } // don't accept directories.\n\n\n    files = files.filter(function (filtered) {\n      return !filtered.match(/\\/$/);\n    });\n\n    if (!files.length) {\n      return cb();\n    }\n\n    var fn = preferMarkdownReadme(files);\n    var rm = path.resolve(dir, fn);\n    readme_(file, data, rm, cb);\n  });\n}\n\nfunction preferMarkdownReadme(files) {\n  var fallback = 0;\n  var re = /\\.m?a?r?k?d?o?w?n?$/i;\n\n  for (var i = 0; i < files.length; i++) {\n    if (files[i].match(re)) {\n      return files[i];\n    } else if (files[i].match(/README$/)) {\n      fallback = i;\n    }\n  } // prefer README.md, followed by README; otherwise, return\n  // the first filename (which could be README)\n\n\n  return files[fallback];\n}\n\nfunction readme_(file, data, rm, cb) {\n  var rmfn = path.basename(rm);\n  fs.readFile(rm, 'utf8', function (er, rmData) {\n    // maybe not readable, or something.\n    if (er) {\n      return cb();\n    }\n\n    data.readme = rmData;\n    data.readmeFilename = rmfn;\n    return cb(er, data);\n  });\n}\n\nfunction mans(file, data, cb) {\n  let cwd = data.directories && data.directories.man;\n\n  if (data.man || !cwd) {\n    return cb(null, data);\n  }\n\n  const dirname = path.dirname(file);\n  cwd = path.resolve(path.dirname(file), cwd);\n  glob('**/*.[0-9]', {\n    cwd\n  }, function (er, mansGlob) {\n    if (er) {\n      return cb(er);\n    }\n\n    data.man = mansGlob.map(man => path.relative(dirname, path.join(cwd, man)).split(path.sep).join('/'));\n    return cb(null, data);\n  });\n}\n\nfunction bins(file, data, cb) {\n  data = normalizePackageBin(data);\n  var m = data.directories && data.directories.bin;\n\n  if (data.bin || !m) {\n    return cb(null, data);\n  }\n\n  m = path.resolve(path.dirname(file), m);\n  glob('**', {\n    cwd: m\n  }, function (er, binsGlob) {\n    if (er) {\n      return cb(er);\n    }\n\n    bins_(file, data, binsGlob, cb);\n  });\n}\n\nfunction bins_(file, data, binsGlob, cb) {\n  var m = data.directories && data.directories.bin || '.';\n  data.bin = binsGlob.reduce(function (acc, mf) {\n    if (mf && mf.charAt(0) !== '.') {\n      var f = path.basename(mf);\n      acc[f] = path.join(m, mf);\n    }\n\n    return acc;\n  }, {});\n  return cb(null, normalizePackageBin(data));\n}\n\nfunction bundleDependencies(file, data, cb) {\n  var bd = 'bundleDependencies';\n  var bdd = 'bundledDependencies'; // normalize key name\n\n  if (data[bdd] !== undefined) {\n    if (data[bd] === undefined) {\n      data[bd] = data[bdd];\n    }\n\n    delete data[bdd];\n  }\n\n  if (data[bd] === false) {\n    delete data[bd];\n  } else if (data[bd] === true) {\n    data[bd] = Object.keys(data.dependencies || {});\n  } else if (data[bd] !== undefined && !Array.isArray(data[bd])) {\n    delete data[bd];\n  }\n\n  return cb(null, data);\n}\n\nfunction githead(file, data, cb) {\n  if (data.gitHead) {\n    return cb(null, data);\n  }\n\n  var dir = path.dirname(file);\n  var head = path.resolve(dir, '.git/HEAD');\n  fs.readFile(head, 'utf8', function (er, headData) {\n    if (er) {\n      var parent = path.dirname(dir);\n\n      if (parent === dir) {\n        return cb(null, data);\n      }\n\n      return githead(dir, data, cb);\n    }\n\n    githead_(data, dir, headData, cb);\n  });\n}\n\nfunction githead_(data, dir, head, cb) {\n  if (!head.match(/^ref: /)) {\n    data.gitHead = head.trim();\n    return cb(null, data);\n  }\n\n  var headRef = head.replace(/^ref: /, '').trim();\n  var headFile = path.resolve(dir, '.git', headRef);\n  fs.readFile(headFile, 'utf8', function (er, headData) {\n    if (er || !headData) {\n      var packFile = path.resolve(dir, '.git/packed-refs');\n      return fs.readFile(packFile, 'utf8', function (readFileErr, refs) {\n        if (readFileErr || !refs) {\n          return cb(null, data);\n        }\n\n        refs = refs.split('\\n');\n\n        for (var i = 0; i < refs.length; i++) {\n          var match = refs[i].match(/^([0-9a-f]{40}) (.+)$/);\n\n          if (match && match[2].trim() === headRef) {\n            data.gitHead = match[1];\n            break;\n          }\n        }\n\n        return cb(null, data);\n      });\n    }\n\n    headData = headData.replace(/^ref: /, '').trim();\n    data.gitHead = headData;\n    return cb(null, data);\n  });\n}\n/**\n * Warn if the bin references don't point to anything.  This might be better in\n * normalize-package-data if it had access to the file path.\n */\n\n\nfunction checkBinReferences_(file, data, warn, cb) {\n  if (!(data.bin instanceof Object)) {\n    return cb();\n  }\n\n  var keys = Object.keys(data.bin);\n  var keysLeft = keys.length;\n\n  if (!keysLeft) {\n    return cb();\n  }\n\n  function handleExists(relName, result) {\n    keysLeft--;\n\n    if (!result) {\n      warn('No bin file found at ' + relName);\n    }\n\n    if (!keysLeft) {\n      cb();\n    }\n  }\n\n  keys.forEach(function (key) {\n    var dirName = path.dirname(file);\n    var relName = data.bin[key];\n    /* istanbul ignore if - impossible, bins have been normalized */\n\n    if (typeof relName !== 'string') {\n      var msg = 'Bin filename for ' + key + ' is not a string: ' + util.inspect(relName);\n      warn(msg);\n      delete data.bin[key];\n      handleExists(relName, true);\n      return;\n    }\n\n    var binPath = path.resolve(dirName, relName);\n    fs.stat(binPath, err => handleExists(relName, !err));\n  });\n}\n\nfunction final(file, data, log, strict, cb) {\n  var pId = makePackageId(data);\n\n  function warn(msg) {\n    if (typoWarned[pId]) {\n      return;\n    }\n\n    if (log) {\n      log('package.json', pId, msg);\n    }\n  }\n\n  try {\n    normalizeData(data, warn, strict);\n  } catch (error) {\n    return cb(error);\n  }\n\n  checkBinReferences_(file, data, warn, function () {\n    typoWarned[pId] = true;\n    cb(null, data);\n  });\n}\n\nfunction fillTypes(file, data, cb) {\n  var index = data.main ? data.main : 'index.js';\n\n  if (typeof index !== 'string') {\n    return cb(new TypeError('The \"main\" attribute must be of type string.'));\n  } // TODO exports is much more complicated than this in verbose format\n  // We need to support for instance\n  // \"exports\": {\n  //   \".\": [\n  //     {\n  //       \"default\": \"./lib/npm.js\"\n  //     },\n  //     \"./lib/npm.js\"\n  //   ],\n  //   \"./package.json\": \"./package.json\"\n  // },\n  // as well as conditional exports\n  // if (data.exports && typeof data.exports === 'string') {\n  //   index = data.exports\n  // }\n  // if (data.exports && data.exports['.']) {\n  //   index = data.exports['.']\n  //   if (typeof index !== 'string') {\n  //   }\n  // }\n\n\n  var extless = path.join(path.dirname(index), path.basename(index, path.extname(index)));\n  var dts = `./${extless}.d.ts`;\n  var dtsPath = path.join(path.dirname(file), dts);\n  var hasDTSFields = 'types' in data || 'typings' in data;\n\n  if (!hasDTSFields && fs.existsSync(dtsPath)) {\n    data.types = dts.split(path.sep).join('/');\n  }\n\n  cb(null, data);\n}\n\nfunction makePackageId(data) {\n  var name = cleanString(data.name);\n  var ver = cleanString(data.version);\n  return name + '@' + ver;\n}\n\nfunction cleanString(str) {\n  return !str || typeof str !== 'string' ? '' : str.trim();\n} // /**package { \"name\": \"foo\", \"version\": \"1.2.3\", ... } **/\n\n\nfunction parseIndex(data) {\n  data = data.split(/^\\/\\*\\*package(?:\\s|$)/m);\n\n  if (data.length < 2) {\n    return null;\n  }\n\n  data = data[1];\n  data = data.split(/\\*\\*\\/$/m);\n\n  if (data.length < 2) {\n    return null;\n  }\n\n  data = data[0];\n  data = data.replace(/^\\s*\\*/mg, '');\n\n  try {\n    return safeJSON(data);\n  } catch (er) {\n    return null;\n  }\n}\n\nfunction parseError(ex, file) {\n  var e = new Error('Failed to parse json\\n' + ex.message);\n  e.code = 'EJSONPARSE';\n  e.path = file;\n  return e;\n}","map":null,"metadata":{},"sourceType":"script"}