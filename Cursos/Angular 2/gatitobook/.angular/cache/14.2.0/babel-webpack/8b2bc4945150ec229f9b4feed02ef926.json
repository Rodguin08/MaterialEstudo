{"ast":null,"code":"var _asyncToGenerator = require(\"C:/Users/Voluti/Desktop/Git/Cursos/Angular 2/gatitobook/node_modules/@babel/runtime/helpers/asyncToGenerator.js\").default;\n\n// This is the base class that the other fetcher types in lib\n// all descend from.\n// It handles the unpacking and retry logic that is shared among\n// all of the other Fetcher types.\nconst npa = require('npm-package-arg');\n\nconst ssri = require('ssri');\n\nconst {\n  promisify\n} = require('util');\n\nconst {\n  basename,\n  dirname\n} = require('path');\n\nconst rimraf = promisify(require('rimraf'));\n\nconst tar = require('tar');\n\nconst log = require('proc-log');\n\nconst retry = require('promise-retry');\n\nconst fsm = require('fs-minipass');\n\nconst cacache = require('cacache');\n\nconst isPackageBin = require('./util/is-package-bin.js');\n\nconst removeTrailingSlashes = require('./util/trailing-slashes.js');\n\nconst getContents = require('@npmcli/installed-package-contents');\n\nconst readPackageJsonFast = require('read-package-json-fast');\n\nconst readPackageJson = promisify(require('read-package-json'));\n\nconst Minipass = require('minipass'); // we only change ownership on unix platforms, and only if uid is 0\n\n\nconst selfOwner = process.getuid && process.getuid() === 0 ? {\n  uid: 0,\n  gid: process.getgid()\n} : null;\nconst chownr = selfOwner ? promisify(require('chownr')) : null;\nconst inferOwner = selfOwner ? require('infer-owner') : null;\n\nconst mkdirp = require('mkdirp');\n\nconst cacheDir = require('./util/cache-dir.js'); // Private methods.\n// Child classes should not have to override these.\n// Users should never call them.\n\n\nconst _chown = Symbol('_chown');\n\nconst _extract = Symbol('_extract');\n\nconst _mkdir = Symbol('_mkdir');\n\nconst _empty = Symbol('_empty');\n\nconst _toFile = Symbol('_toFile');\n\nconst _tarxOptions = Symbol('_tarxOptions');\n\nconst _entryMode = Symbol('_entryMode');\n\nconst _istream = Symbol('_istream');\n\nconst _assertType = Symbol('_assertType');\n\nconst _tarballFromCache = Symbol('_tarballFromCache');\n\nconst _tarballFromResolved = Symbol.for('pacote.Fetcher._tarballFromResolved');\n\nconst _cacheFetches = Symbol.for('pacote.Fetcher._cacheFetches');\n\nconst _readPackageJson = Symbol.for('package.Fetcher._readPackageJson');\n\nclass FetcherBase {\n  constructor(spec, opts) {\n    if (!opts || typeof opts !== 'object') {\n      throw new TypeError('options object is required');\n    }\n\n    this.spec = npa(spec, opts.where);\n    this.allowGitIgnore = !!opts.allowGitIgnore; // a bit redundant because presumably the caller already knows this,\n    // but it makes it easier to not have to keep track of the requested\n    // spec when we're dispatching thousands of these at once, and normalizing\n    // is nice.  saveSpec is preferred if set, because it turns stuff like\n    // x/y#committish into github:x/y#committish.  use name@rawSpec for\n    // registry deps so that we turn xyz and xyz@ -> xyz@\n\n    this.from = this.spec.registry ? `${this.spec.name}@${this.spec.rawSpec}` : this.spec.saveSpec;\n\n    this[_assertType](); // clone the opts object so that others aren't upset when we mutate it\n    // by adding/modifying the integrity value.\n\n\n    this.opts = { ...opts\n    };\n    this.cache = opts.cache || cacheDir();\n    this.resolved = opts.resolved || null; // default to caching/verifying with sha512, that's what we usually have\n    // need to change this default, or start overriding it, when sha512\n    // is no longer strong enough.\n\n    this.defaultIntegrityAlgorithm = opts.defaultIntegrityAlgorithm || 'sha512';\n\n    if (typeof opts.integrity === 'string') {\n      this.opts.integrity = ssri.parse(opts.integrity);\n    }\n\n    this.package = null;\n    this.type = this.constructor.name;\n    this.fmode = opts.fmode || 0o666;\n    this.dmode = opts.dmode || 0o777; // we don't need a default umask, because we don't chmod files coming\n    // out of package tarballs.  they're forced to have a mode that is\n    // valid, regardless of what's in the tarball entry, and then we let\n    // the process's umask setting do its job.  but if configured, we do\n    // respect it.\n\n    this.umask = opts.umask || 0;\n    this.preferOnline = !!opts.preferOnline;\n    this.preferOffline = !!opts.preferOffline;\n    this.offline = !!opts.offline;\n    this.before = opts.before;\n    this.fullMetadata = this.before ? true : !!opts.fullMetadata;\n    this.fullReadJson = !!opts.fullReadJson;\n\n    if (this.fullReadJson) {\n      this[_readPackageJson] = readPackageJson;\n    } else {\n      this[_readPackageJson] = readPackageJsonFast;\n    } // rrh is a registry hostname or 'never' or 'always'\n    // defaults to registry.npmjs.org\n\n\n    this.replaceRegistryHost = !opts.replaceRegistryHost || opts.replaceRegistryHost === 'npmjs' ? 'registry.npmjs.org' : opts.replaceRegistryHost;\n    this.defaultTag = opts.defaultTag || 'latest';\n    this.registry = removeTrailingSlashes(opts.registry || 'https://registry.npmjs.org'); // command to run 'prepare' scripts on directories and git dirs\n    // To use pacote with yarn, for example, set npmBin to 'yarn'\n    // and npmCliConfig with yarn's equivalents.\n\n    this.npmBin = opts.npmBin || 'npm'; // command to install deps for preparing\n\n    this.npmInstallCmd = opts.npmInstallCmd || ['install', '--force']; // XXX fill more of this in based on what we know from this.opts\n    // we explicitly DO NOT fill in --tag, though, since we are often\n    // going to be packing in the context of a publish, which may set\n    // a dist-tag, but certainly wants to keep defaulting to latest.\n\n    this.npmCliConfig = opts.npmCliConfig || [`--cache=${dirname(this.cache)}`, `--prefer-offline=${!!this.preferOffline}`, `--prefer-online=${!!this.preferOnline}`, `--offline=${!!this.offline}`, ...(this.before ? [`--before=${this.before.toISOString()}`] : []), '--no-progress', '--no-save', '--no-audit', // override any omit settings from the environment\n    '--include=dev', '--include=peer', '--include=optional', // we need the actual things, not just the lockfile\n    '--no-package-lock-only', '--no-dry-run'];\n  }\n\n  get integrity() {\n    return this.opts.integrity || null;\n  }\n\n  set integrity(i) {\n    if (!i) {\n      return;\n    }\n\n    i = ssri.parse(i);\n    const current = this.opts.integrity; // do not ever update an existing hash value, but do\n    // merge in NEW algos and hashes that we don't already have.\n\n    if (current) {\n      current.merge(i);\n    } else {\n      this.opts.integrity = i;\n    }\n  }\n\n  get notImplementedError() {\n    return new Error('not implemented in this fetcher type: ' + this.type);\n  } // override in child classes\n  // Returns a Promise that resolves to this.resolved string value\n\n\n  resolve() {\n    return this.resolved ? Promise.resolve(this.resolved) : Promise.reject(this.notImplementedError);\n  }\n\n  packument() {\n    return Promise.reject(this.notImplementedError);\n  } // override in child class\n  // returns a manifest containing:\n  // - name\n  // - version\n  // - _resolved\n  // - _integrity\n  // - plus whatever else was in there (corgi, full metadata, or pj file)\n\n\n  manifest() {\n    return Promise.reject(this.notImplementedError);\n  } // private, should be overridden.\n  // Note that they should *not* calculate or check integrity or cache,\n  // but *just*  return the raw tarball data stream.\n\n\n  [_tarballFromResolved]() {\n    throw this.notImplementedError;\n  } // public, should not be overridden\n\n\n  tarball() {\n    return this.tarballStream(stream => stream.concat().then(data => {\n      data.integrity = this.integrity && String(this.integrity);\n      data.resolved = this.resolved;\n      data.from = this.from;\n      return data;\n    }));\n  } // private\n  // Note: cacache will raise a EINTEGRITY error if the integrity doesn't match\n\n\n  [_tarballFromCache]() {\n    return cacache.get.stream.byDigest(this.cache, this.integrity, this.opts);\n  }\n\n  get [_cacheFetches]() {\n    return true;\n  }\n\n  [_istream](stream) {\n    // if not caching this, just return it\n    if (!this.opts.cache || !this[_cacheFetches]) {\n      // instead of creating a new integrity stream, we only piggyback on the\n      // provided stream's events\n      if (stream.hasIntegrityEmitter) {\n        stream.on('integrity', i => this.integrity = i);\n        return stream;\n      }\n\n      const istream = ssri.integrityStream(this.opts);\n      istream.on('integrity', i => this.integrity = i);\n      stream.on('error', err => istream.emit('error', err));\n      return stream.pipe(istream);\n    } // we have to return a stream that gets ALL the data, and proxies errors,\n    // but then pipe from the original tarball stream into the cache as well.\n    // To do this without losing any data, and since the cacache put stream\n    // is not a passthrough, we have to pipe from the original stream into\n    // the cache AFTER we pipe into the middleStream.  Since the cache stream\n    // has an asynchronous flush to write its contents to disk, we need to\n    // defer the middleStream end until the cache stream ends.\n\n\n    const middleStream = new Minipass();\n    stream.on('error', err => middleStream.emit('error', err));\n    stream.pipe(middleStream, {\n      end: false\n    });\n    const cstream = cacache.put.stream(this.opts.cache, `pacote:tarball:${this.from}`, this.opts);\n    cstream.on('integrity', i => this.integrity = i);\n    cstream.on('error', err => stream.emit('error', err));\n    stream.pipe(cstream); // eslint-disable-next-line promise/catch-or-return\n\n    cstream.promise().catch(() => {}).then(() => middleStream.end());\n    return middleStream;\n  }\n\n  pickIntegrityAlgorithm() {\n    return this.integrity ? this.integrity.pickAlgorithm(this.opts) : this.defaultIntegrityAlgorithm;\n  } // TODO: check error class, once those are rolled out to our deps\n\n\n  isDataCorruptionError(er) {\n    return er.code === 'EINTEGRITY' || er.code === 'Z_DATA_ERROR';\n  } // override the types getter\n\n\n  get types() {\n    return false;\n  }\n\n  [_assertType]() {\n    if (this.types && !this.types.includes(this.spec.type)) {\n      throw new TypeError(`Wrong spec type (${this.spec.type}) for ${this.constructor.name}. Supported types: ${this.types.join(', ')}`);\n    }\n  } // We allow ENOENTs from cacache, but not anywhere else.\n  // An ENOENT trying to read a tgz file, for example, is Right Out.\n\n\n  isRetriableError(er) {\n    // TODO: check error class, once those are rolled out to our deps\n    return this.isDataCorruptionError(er) || er.code === 'ENOENT' || er.code === 'EISDIR';\n  } // Mostly internal, but has some uses\n  // Pass in a function which returns a promise\n  // Function will be called 1 or more times with streams that may fail.\n  // Retries:\n  // Function MUST handle errors on the stream by rejecting the promise,\n  // so that retry logic can pick it up and either retry or fail whatever\n  // promise it was making (ie, failing extraction, etc.)\n  //\n  // The return value of this method is a Promise that resolves the same\n  // as whatever the streamHandler resolves to.\n  //\n  // This should never be overridden by child classes, but it is public.\n\n\n  tarballStream(streamHandler) {\n    // Only short-circuit via cache if we have everything else we'll need,\n    // and the user has not expressed a preference for checking online.\n    const fromCache = !this.preferOnline && this.integrity && this.resolved ? streamHandler(this[_tarballFromCache]()).catch(er => {\n      if (this.isDataCorruptionError(er)) {\n        log.warn('tarball', `cached data for ${this.spec} (${this.integrity}) seems to be corrupted. Refreshing cache.`);\n        return this.cleanupCached().then(() => {\n          throw er;\n        });\n      } else {\n        throw er;\n      }\n    }) : null;\n\n    const fromResolved = er => {\n      if (er) {\n        if (!this.isRetriableError(er)) {\n          throw er;\n        }\n\n        log.silly('tarball', `no local data for ${this.spec}. Extracting by manifest.`);\n      }\n\n      return this.resolve().then(() => retry(tryAgain => streamHandler(this[_istream](this[_tarballFromResolved]())).catch(streamErr => {\n        // Most likely data integrity.  A cache ENOENT error is unlikely\n        // here, since we're definitely not reading from the cache, but it\n        // IS possible that the fetch subsystem accessed the cache, and the\n        // entry got blown away or something.  Try one more time to be sure.\n        if (this.isRetriableError(streamErr)) {\n          log.warn('tarball', `tarball data for ${this.spec} (${this.integrity}) seems to be corrupted. Trying again.`);\n          return this.cleanupCached().then(() => tryAgain(streamErr));\n        }\n\n        throw streamErr;\n      }), {\n        retries: 1,\n        minTimeout: 0,\n        maxTimeout: 0\n      }));\n    };\n\n    return fromCache ? fromCache.catch(fromResolved) : fromResolved();\n  }\n\n  cleanupCached() {\n    return cacache.rm.content(this.cache, this.integrity, this.opts);\n  }\n\n  [_chown](path, uid, gid) {\n    return _asyncToGenerator(function* () {\n      return selfOwner && (selfOwner.gid !== gid || selfOwner.uid !== uid) ? chownr(path, uid, gid) :\n      /* istanbul ignore next - we don't test in root-owned folders */\n      null;\n    })();\n  }\n\n  [_empty](path) {\n    return getContents({\n      path,\n      depth: 1\n    }).then(contents => Promise.all(contents.map(entry => rimraf(entry))));\n  }\n\n  [_mkdir](dest) {\n    // if we're bothering to do owner inference, then do it.\n    // otherwise just make the dir, and return an empty object.\n    // always empty the dir dir to start with, but do so\n    // _after_ inferring the owner, in case there's an existing folder\n    // there that we would want to preserve which differs from the\n    // parent folder (rare, but probably happens sometimes).\n    return !inferOwner ? this[_empty](dest).then(() => mkdirp(dest)).then(() => ({})) : inferOwner(dest).then(({\n      uid,\n      gid\n    }) => this[_empty](dest).then(() => mkdirp(dest)).then(made => {\n      // ignore the || dest part in coverage.  It's there to handle\n      // race conditions where the dir may be made by someone else\n      // after being removed by us.\n      const dir = made ||\n      /* istanbul ignore next */\n      dest;\n      return this[_chown](dir, uid, gid);\n    }).then(() => ({\n      uid,\n      gid\n    })));\n  } // extraction is always the same.  the only difference is where\n  // the tarball comes from.\n\n\n  extract(dest) {\n    return this[_mkdir](dest).then(({\n      uid,\n      gid\n    }) => this.tarballStream(tarball => this[_extract](dest, tarball, uid, gid)));\n  }\n\n  [_toFile](dest) {\n    return this.tarballStream(str => new Promise((res, rej) => {\n      const writer = new fsm.WriteStream(dest);\n      str.on('error', er => writer.emit('error', er));\n      writer.on('error', er => rej(er));\n      writer.on('close', () => res({\n        integrity: this.integrity && String(this.integrity),\n        resolved: this.resolved,\n        from: this.from\n      }));\n      str.pipe(writer);\n    }));\n  } // don't use this[_mkdir] because we don't want to rimraf anything\n\n\n  tarballFile(dest) {\n    const dir = dirname(dest);\n    return !inferOwner ? mkdirp(dir).then(() => this[_toFile](dest)) : inferOwner(dest).then(({\n      uid,\n      gid\n    }) => mkdirp(dir).then(made => this[_toFile](dest).then(res => this[_chown](made || dir, uid, gid).then(() => res))));\n  }\n\n  [_extract](dest, tarball, uid, gid) {\n    const extractor = tar.x(this[_tarxOptions]({\n      cwd: dest,\n      uid,\n      gid\n    }));\n    const p = new Promise((resolve, reject) => {\n      extractor.on('end', () => {\n        resolve({\n          resolved: this.resolved,\n          integrity: this.integrity && String(this.integrity),\n          from: this.from\n        });\n      });\n      extractor.on('error', er => {\n        log.warn('tar', er.message);\n        log.silly('tar', er);\n        reject(er);\n      });\n      tarball.on('error', er => reject(er));\n    });\n    tarball.pipe(extractor);\n    return p;\n  } // always ensure that entries are at least as permissive as our configured\n  // dmode/fmode, but never more permissive than the umask allows.\n\n\n  [_entryMode](path, mode, type) {\n    const m = /Directory|GNUDumpDir/.test(type) ? this.dmode : /File$/.test(type) ? this.fmode :\n    /* istanbul ignore next - should never happen in a pkg */\n    0; // make sure package bins are executable\n\n    const exe = isPackageBin(this.package, path) ? 0o111 : 0; // always ensure that files are read/writable by the owner\n\n    return (mode | m) & ~this.umask | exe | 0o600;\n  }\n\n  [_tarxOptions]({\n    cwd,\n    uid,\n    gid\n  }) {\n    const sawIgnores = new Set();\n    return {\n      cwd,\n      noChmod: true,\n      noMtime: true,\n      filter: (name, entry) => {\n        if (/Link$/.test(entry.type)) {\n          return false;\n        }\n\n        entry.mode = this[_entryMode](entry.path, entry.mode, entry.type); // this replicates the npm pack behavior where .gitignore files\n        // are treated like .npmignore files, but only if a .npmignore\n        // file is not present.\n\n        if (/File$/.test(entry.type)) {\n          const base = basename(entry.path);\n\n          if (base === '.npmignore') {\n            sawIgnores.add(entry.path);\n          } else if (base === '.gitignore' && !this.allowGitIgnore) {\n            // rename, but only if there's not already a .npmignore\n            const ni = entry.path.replace(/\\.gitignore$/, '.npmignore');\n\n            if (sawIgnores.has(ni)) {\n              return false;\n            }\n\n            entry.path = ni;\n          }\n\n          return true;\n        }\n      },\n      strip: 1,\n      onwarn:\n      /* istanbul ignore next - we can trust that tar logs */\n      (code, msg, data) => {\n        log.warn('tar', code, msg);\n        log.silly('tar', code, msg, data);\n      },\n      uid,\n      gid,\n      umask: this.umask\n    };\n  }\n\n}\n\nmodule.exports = FetcherBase; // Child classes\n\nconst GitFetcher = require('./git.js');\n\nconst RegistryFetcher = require('./registry.js');\n\nconst FileFetcher = require('./file.js');\n\nconst DirFetcher = require('./dir.js');\n\nconst RemoteFetcher = require('./remote.js'); // Get an appropriate fetcher object from a spec and options\n\n\nFetcherBase.get = (rawSpec, opts = {}) => {\n  const spec = npa(rawSpec, opts.where);\n\n  switch (spec.type) {\n    case 'git':\n      return new GitFetcher(spec, opts);\n\n    case 'remote':\n      return new RemoteFetcher(spec, opts);\n\n    case 'version':\n    case 'range':\n    case 'tag':\n    case 'alias':\n      return new RegistryFetcher(spec.subSpec || spec, opts);\n\n    case 'file':\n      return new FileFetcher(spec, opts);\n\n    case 'directory':\n      return new DirFetcher(spec, opts);\n\n    default:\n      throw new TypeError('Unknown spec type: ' + spec.type);\n  }\n};","map":null,"metadata":{},"sourceType":"script"}