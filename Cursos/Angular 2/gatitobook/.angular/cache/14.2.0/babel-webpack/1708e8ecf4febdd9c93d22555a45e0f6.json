{"ast":null,"code":"var _asyncToGenerator = require(\"C:/Users/Voluti/Desktop/Git/Cursos/Angular 2/gatitobook/node_modules/@babel/runtime/helpers/asyncToGenerator.js\").default;\n\n// to GET CONTENTS for folder at PATH (which may be a PACKAGE):\n// - if PACKAGE, read path/package.json\n//   - if bins in ../node_modules/.bin, add those to result\n// - if depth >= maxDepth, add PATH to result, and finish\n// - readdir(PATH, with file types)\n// - add all FILEs in PATH to result\n// - if PARENT:\n//   - if depth < maxDepth, add GET CONTENTS of all DIRs in PATH\n//   - else, add all DIRs in PATH\n// - if no parent\n//   - if no bundled deps,\n//     - if depth < maxDepth, add GET CONTENTS of DIRs in path except\n//       node_modules\n//     - else, add all DIRs in path other than node_modules\n//   - if has bundled deps,\n//     - get list of bundled deps\n//     - add GET CONTENTS of bundled deps, PACKAGE=true, depth + 1\nconst bundled = require('npm-bundled');\n\nconst {\n  promisify\n} = require('util');\n\nconst fs = require('fs');\n\nconst readFile = promisify(fs.readFile);\nconst readdir = promisify(fs.readdir);\nconst stat = promisify(fs.stat);\nconst lstat = promisify(fs.lstat);\n\nconst {\n  relative,\n  resolve,\n  basename,\n  dirname\n} = require('path');\n\nconst normalizePackageBin = require('npm-normalize-package-bin');\n\nconst readPackage = ({\n  path,\n  packageJsonCache\n}) => packageJsonCache.has(path) ? Promise.resolve(packageJsonCache.get(path)) : readFile(path).then(json => {\n  const pkg = normalizePackageBin(JSON.parse(json));\n  packageJsonCache.set(path, pkg);\n  return pkg;\n}).catch(er => null); // just normalize bundle deps and bin, that's all we care about here.\n\n\nconst normalized = Symbol('package data has been normalized');\n\nconst rpj = ({\n  path,\n  packageJsonCache\n}) => readPackage({\n  path,\n  packageJsonCache\n}).then(pkg => {\n  if (!pkg || pkg[normalized]) return pkg;\n\n  if (pkg.bundledDependencies && !pkg.bundleDependencies) {\n    pkg.bundleDependencies = pkg.bundledDependencies;\n    delete pkg.bundledDependencies;\n  }\n\n  const bd = pkg.bundleDependencies;\n\n  if (bd === true) {\n    pkg.bundleDependencies = [...Object.keys(pkg.dependencies || {}), ...Object.keys(pkg.optionalDependencies || {})];\n  }\n\n  if (typeof bd === 'object' && !Array.isArray(bd)) {\n    pkg.bundleDependencies = Object.keys(bd);\n  }\n\n  pkg[normalized] = true;\n  return pkg;\n});\n\nconst pkgContents = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator(function* ({\n    path,\n    depth,\n    currentDepth = 0,\n    pkg = null,\n    result = null,\n    packageJsonCache = null\n  }) {\n    if (!result) result = new Set();\n    if (!packageJsonCache) packageJsonCache = new Map();\n\n    if (pkg === true) {\n      return rpj({\n        path: path + '/package.json',\n        packageJsonCache\n      }).then(pkg => pkgContents({\n        path,\n        depth,\n        currentDepth,\n        pkg,\n        result,\n        packageJsonCache\n      }));\n    }\n\n    if (pkg) {\n      // add all bins to result if they exist\n      if (pkg.bin) {\n        const dir = dirname(path);\n        const base = basename(path);\n        const scope = basename(dir);\n        const nm = /^@.+/.test(scope) ? dirname(dir) : dir;\n        const binFiles = [];\n        Object.keys(pkg.bin).forEach(b => {\n          const base = resolve(nm, '.bin', b);\n          binFiles.push(base, base + '.cmd', base + '.ps1');\n        });\n        const bins = yield Promise.all(binFiles.map(b => stat(b).then(() => b).catch(er => null)));\n        bins.filter(b => b).forEach(b => result.add(b));\n      }\n    }\n\n    if (currentDepth >= depth) {\n      result.add(path);\n      return result;\n    } // we'll need bundle list later, so get that now in parallel\n\n\n    const [dirEntries, bundleDeps] = yield Promise.all([readdir(path, {\n      withFileTypes: true\n    }), currentDepth === 0 && pkg && pkg.bundleDependencies ? bundled({\n      path,\n      packageJsonCache\n    }) : null]).catch(() => []); // not a thing, probably a missing folder\n\n    if (!dirEntries) return result; // empty folder, just add the folder itself to the result\n\n    if (!dirEntries.length && !bundleDeps && currentDepth !== 0) {\n      result.add(path);\n      return result;\n    }\n\n    const recursePromises = []; // if we didn't get withFileTypes support, tack that on\n\n    if (typeof dirEntries[0] === 'string') {\n      // use a map so we can return a promise, but we mutate dirEntries in place\n      // this is much slower than getting the entries from the readdir call,\n      // but polyfills support for node versions before 10.10\n      yield Promise.all(dirEntries.map( /*#__PURE__*/function () {\n        var _ref2 = _asyncToGenerator(function* (name, index) {\n          const p = resolve(path, name);\n          const st = yield lstat(p);\n          dirEntries[index] = Object.assign(st, {\n            name\n          });\n        });\n\n        return function (_x2, _x3) {\n          return _ref2.apply(this, arguments);\n        };\n      }()));\n    }\n\n    for (const entry of dirEntries) {\n      const p = resolve(path, entry.name);\n\n      if (entry.isDirectory() === false) {\n        result.add(p);\n        continue;\n      }\n\n      if (currentDepth !== 0 || entry.name !== 'node_modules') {\n        if (currentDepth < depth - 1) {\n          recursePromises.push(pkgContents({\n            path: p,\n            packageJsonCache,\n            depth,\n            currentDepth: currentDepth + 1,\n            result\n          }));\n        } else {\n          result.add(p);\n        }\n\n        continue;\n      }\n    }\n\n    if (bundleDeps) {\n      // bundle deps are all folders\n      // we always recurse to get pkg bins, but if currentDepth is too high,\n      // it'll return early before walking their contents.\n      recursePromises.push(...bundleDeps.map(dep => {\n        const p = resolve(path, 'node_modules', dep);\n        return pkgContents({\n          path: p,\n          packageJsonCache,\n          pkg: true,\n          depth,\n          currentDepth: currentDepth + 1,\n          result\n        });\n      }));\n    }\n\n    if (recursePromises.length) yield Promise.all(recursePromises);\n    return result;\n  });\n\n  return function pkgContents(_x) {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nmodule.exports = ({\n  path,\n  depth = 1,\n  packageJsonCache\n}) => pkgContents({\n  path: resolve(path),\n  depth,\n  pkg: true,\n  packageJsonCache\n}).then(results => [...results]);\n\nif (require.main === module) {\n  const options = {\n    path: null,\n    depth: 1\n  };\n  const usage = `Usage:\n  installed-package-contents <path> [-d<n> --depth=<n>]\n\nLists the files installed for a package specified by <path>.\n\nOptions:\n  -d<n> --depth=<n>   Provide a numeric value (\"Infinity\" is allowed)\n                      to specify how deep in the file tree to traverse.\n                      Default=1\n  -h --help           Show this usage information`;\n  process.argv.slice(2).forEach(arg => {\n    let match;\n    if ((match = arg.match(/^--depth=([0-9]+|Infinity)/)) || (match = arg.match(/^-d([0-9]+|Infinity)/))) options.depth = +match[1];else if (arg === '-h' || arg === '--help') {\n      console.log(usage);\n      process.exit(0);\n    } else options.path = arg;\n  });\n\n  if (!options.path) {\n    console.error('ERROR: no path provided');\n    console.error(usage);\n    process.exit(1);\n  }\n\n  const cwd = process.cwd();\n  module.exports(options).then(list => list.sort().forEach(p => console.log(relative(cwd, p)))).catch(\n  /* istanbul ignore next - pretty unusual */\n  er => {\n    console.error(er);\n    process.exit(1);\n  });\n}","map":null,"metadata":{},"sourceType":"script"}