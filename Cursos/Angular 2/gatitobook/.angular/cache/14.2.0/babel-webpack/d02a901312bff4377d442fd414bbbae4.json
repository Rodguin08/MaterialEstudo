{"ast":null,"code":"'use strict'; // Do a two-pass walk, first to get the list of packages that need to be\n// bundled, then again to get the actual files and folders.\n// Keep a cache of node_modules content and package.json data, so that the\n// second walk doesn't have to re-do all the same work.\n\nconst bundleWalk = require('npm-bundled');\n\nconst BundleWalker = bundleWalk.BundleWalker;\n\nconst ignoreWalk = require('ignore-walk');\n\nconst IgnoreWalker = ignoreWalk.Walker;\nconst rootBuiltinRules = Symbol('root-builtin-rules');\nconst packageNecessaryRules = Symbol('package-necessary-rules');\n\nconst path = require('path');\n\nconst normalizePackageBin = require('npm-normalize-package-bin'); // Weird side-effect of this: a readme (etc) file will be included\n// if it exists anywhere within a folder with a package.json file.\n// The original intent was only to include these files in the root,\n// but now users in the wild are dependent on that behavior for\n// localized documentation and other use cases.  Adding a `/` to\n// these rules, while tempting and arguably more \"correct\", is a\n// significant change that will break existing use cases.\n\n\nconst packageMustHaveFileNames = 'readme|copying|license|licence';\nconst packageMustHaves = `@(${packageMustHaveFileNames}){,.*[^~$]}`;\nconst packageMustHavesRE = new RegExp(`^(${packageMustHaveFileNames})(\\\\..*[^~$])?$`, 'i');\n\nconst fs = require('fs');\n\nconst glob = require('glob');\n\nconst globify = pattern => pattern.split('\\\\').join('/');\n\nconst readOutOfTreeIgnoreFiles = (root, rel, result = '') => {\n  for (const file of ['.npmignore', '.gitignore']) {\n    try {\n      const ignoreContent = fs.readFileSync(path.join(root, file), {\n        encoding: 'utf8'\n      });\n      result += ignoreContent + '\\n'; // break the loop immediately after concatting, this allows us to prioritize the\n      // .npmignore and discard the .gitignore if one exists\n\n      break;\n    } catch (err) {\n      // we ignore ENOENT errors completely because we don't care if the file doesn't exist\n      // but we throw everything else because failing to read a file that does exist is\n      // something that the user likely wants to know about. we don't need to test this.\n\n      /* istanbul ignore next */\n      if (err.code !== 'ENOENT') {\n        throw err;\n      }\n    }\n  }\n\n  if (!rel) {\n    return result;\n  }\n\n  const firstRel = rel.split(path.sep)[0];\n  const newRoot = path.join(root, firstRel);\n  const newRel = path.relative(newRoot, path.join(root, rel));\n  return readOutOfTreeIgnoreFiles(newRoot, newRel, result);\n};\n\nconst pathHasPkg = input => {\n  if (!input.startsWith('node_modules/')) {\n    return false;\n  }\n\n  const segments = input.slice('node_modules/'.length).split('/', 2);\n  return segments[0].startsWith('@') ? segments.length === 2 : true;\n};\n\nconst pkgFromPath = input => {\n  const segments = input.slice('node_modules/'.length).split('/', 2);\n  return segments[0].startsWith('@') ? segments.join('/') : segments[0];\n};\n\nconst defaultRules = ['.npmignore', '.gitignore', '**/.git', '**/.svn', '**/.hg', '**/CVS', '**/.git/**', '**/.svn/**', '**/.hg/**', '**/CVS/**', '/.lock-wscript', '/.wafpickle-*', '/build/config.gypi', 'npm-debug.log', '**/.npmrc', '.*.swp', '.DS_Store', '**/.DS_Store/**', '._*', '**/._*/**', '*.orig', '/package-lock.json', '/yarn.lock', '/pnpm-lock.yaml', '/archived-packages/**']; // There may be others, but :?|<> are handled by node-tar\n\nconst nameIsBadForWindows = file => /\\*/.test(file);\n\nclass Walker extends IgnoreWalker {\n  constructor(opt) {\n    opt = opt || {}; // the order in which rules are applied.\n\n    opt.ignoreFiles = [rootBuiltinRules, 'package.json', '.npmignore', '.gitignore', packageNecessaryRules];\n    opt.includeEmpty = false;\n    opt.path = opt.path || process.cwd(); // only follow links in the root node_modules folder, because if those\n    // folders are included, it's because they're bundled, and bundles\n    // should include the contents, not the symlinks themselves.\n    // This regexp tests to see that we're either a node_modules folder,\n    // or a @scope within a node_modules folder, in the root's node_modules\n    // hierarchy (ie, not in test/foo/node_modules/ or something).\n\n    const followRe = /^(?:\\/node_modules\\/(?:@[^/]+\\/[^/]+|[^/]+)\\/)*\\/node_modules(?:\\/@[^/]+)?$/;\n    const rootPath = opt.parent ? opt.parent.root : opt.path;\n    const followTestPath = opt.path.replace(/\\\\/g, '/').slice(rootPath.length);\n    opt.follow = followRe.test(followTestPath);\n    super(opt); // ignore a bunch of things by default at the root level.\n    // also ignore anything in the main project node_modules hierarchy,\n    // except bundled dependencies\n\n    if (this.isProject) {\n      this.bundled = opt.bundled || [];\n      this.bundledScopes = Array.from(new Set(this.bundled.filter(f => /^@/.test(f)).map(f => f.split('/')[0])));\n      this.packageJsonCache = this.parent ? this.parent.packageJsonCache : opt.packageJsonCache || new Map();\n      let rules = defaultRules.join('\\n') + '\\n';\n\n      if (opt.prefix && opt.workspaces) {\n        const gPath = globify(opt.path);\n        const gPrefix = globify(opt.prefix);\n        const gWorkspaces = opt.workspaces.map(ws => globify(ws)); // if opt.path and opt.prefix are not the same directory, and opt.workspaces has opt.path\n        // in it, then we know that opt.path is a workspace directory. in order to not drop ignore\n        // rules from directories between the workspace root (opt.prefix) and the workspace itself\n        // (opt.path), we need to find and read those now\n\n        /* istanbul ignore else */\n\n        if (gPath !== gPrefix && gWorkspaces.includes(gPath)) {\n          // relpath is the relative path between the prefix and the parent of opt.path\n          // we use the parent because ignore-walk will read the files in opt.path already\n          const relpath = path.relative(opt.prefix, path.dirname(opt.path));\n          rules += readOutOfTreeIgnoreFiles(opt.prefix, relpath);\n        } else if (gPath === gPrefix) {\n          // on the other hand, if the path and the prefix are the same, then we ignore workspaces\n          // so that we don't pack workspaces inside of a root project\n          rules += opt.workspaces.map(ws => globify(path.relative(opt.path, ws))).join('\\n');\n        }\n      }\n\n      super.onReadIgnoreFile(rootBuiltinRules, rules, _ => _);\n    } else {\n      this.bundled = [];\n      this.bundledScopes = [];\n      this.packageJsonCache = this.parent.packageJsonCache;\n    }\n  }\n\n  get isProject() {\n    return !this.parent || this.parent.follow && this.isSymbolicLink;\n  }\n\n  onReaddir(entries) {\n    if (this.isProject) {\n      entries = entries.filter(e => e !== '.git' && !(e === 'node_modules' && this.bundled.length === 0));\n    } // if we have a package.json, then look in it for 'files'\n    // we _only_ do this in the root project, not bundled deps\n    // or other random folders.  Bundled deps are always assumed\n    // to be in the state the user wants to include them, and\n    // a package.json somewhere else might be a template or\n    // test or something else entirely.\n\n\n    if (!this.isProject || !entries.includes('package.json')) {\n      return super.onReaddir(entries);\n    } // when the cache has been seeded with the root manifest,\n    // we must respect that (it may differ from the filesystem)\n\n\n    const ig = path.resolve(this.path, 'package.json');\n\n    if (this.packageJsonCache.has(ig)) {\n      const pkg = this.packageJsonCache.get(ig); // fall back to filesystem when seeded manifest is invalid\n\n      if (!pkg || typeof pkg !== 'object') {\n        return this.readPackageJson(entries);\n      } // feels wonky, but this ensures package bin is _always_\n      // normalized, as well as guarding against invalid JSON\n\n\n      return this.getPackageFiles(entries, JSON.stringify(pkg));\n    }\n\n    this.readPackageJson(entries);\n  }\n\n  onReadPackageJson(entries, er, pkg) {\n    if (er) {\n      this.emit('error', er);\n    } else {\n      this.getPackageFiles(entries, pkg);\n    }\n  }\n\n  mustHaveFilesFromPackage(pkg) {\n    const files = [];\n\n    if (pkg.browser) {\n      files.push('/' + pkg.browser);\n    }\n\n    if (pkg.main) {\n      files.push('/' + pkg.main);\n    }\n\n    if (pkg.bin) {\n      // always an object because normalized already\n      for (const key in pkg.bin) {\n        files.push('/' + pkg.bin[key]);\n      }\n    }\n\n    files.push('/package.json', '/npm-shrinkwrap.json', '!/package-lock.json', packageMustHaves);\n    return files;\n  }\n\n  getPackageFiles(entries, pkg) {\n    try {\n      // XXX this could be changed to use read-package-json-fast\n      // which handles the normalizing of bins for us, and simplifies\n      // the test for bundleDependencies and bundledDependencies later.\n      // HOWEVER if we do this, we need to be sure that we're careful\n      // about what we write back out since rpj-fast removes some fields\n      // that the user likely wants to keep. it also would add a second\n      // file read that we would want to optimize away.\n      pkg = normalizePackageBin(JSON.parse(pkg.toString()));\n    } catch (er) {\n      // not actually a valid package.json\n      return super.onReaddir(entries);\n    }\n\n    const ig = path.resolve(this.path, 'package.json');\n    this.packageJsonCache.set(ig, pkg); // no files list, just return the normal readdir() result\n\n    if (!Array.isArray(pkg.files)) {\n      return super.onReaddir(entries);\n    }\n\n    pkg.files.push(...this.mustHaveFilesFromPackage(pkg)); // If the package has a files list, then it's unlikely to include\n    // node_modules, because why would you do that?  but since we use\n    // the files list as the effective readdir result, that means it\n    // looks like we don't have a node_modules folder at all unless we\n    // include it here.\n\n    if ((pkg.bundleDependencies || pkg.bundledDependencies) && entries.includes('node_modules')) {\n      pkg.files.push('node_modules');\n    }\n\n    const patterns = Array.from(new Set(pkg.files)).reduce((set, pattern) => {\n      const excl = pattern.match(/^!+/);\n\n      if (excl) {\n        pattern = pattern.slice(excl[0].length);\n      } // strip off any / or ./ from the start of the pattern.  /foo => foo, ./foo => foo\n\n\n      pattern = pattern.replace(/^\\.?\\/+/, ''); // an odd number of ! means a negated pattern.  !!foo ==> foo\n\n      const negate = excl && excl[0].length % 2 === 1;\n      set.push({\n        pattern,\n        negate\n      });\n      return set;\n    }, []);\n    let n = patterns.length;\n    const set = new Set();\n    const negates = new Set();\n    const results = [];\n\n    const then = (pattern, negate, er, fileList, i) => {\n      if (er) {\n        return this.emit('error', er);\n      }\n\n      results[i] = {\n        negate,\n        fileList\n      };\n\n      if (--n === 0) {\n        processResults(results);\n      }\n    };\n\n    const processResults = processed => {\n      for (const {\n        negate,\n        fileList\n      } of processed) {\n        if (negate) {\n          fileList.forEach(f => {\n            f = f.replace(/\\/+$/, '');\n            set.delete(f);\n            negates.add(f);\n          });\n        } else {\n          fileList.forEach(f => {\n            f = f.replace(/\\/+$/, '');\n            set.add(f);\n            negates.delete(f);\n          });\n        }\n      }\n\n      const list = Array.from(set); // replace the files array with our computed explicit set\n\n      pkg.files = list.concat(Array.from(negates).map(f => '!' + f));\n      const rdResult = Array.from(new Set(list.map(f => f.replace(/^\\/+/, ''))));\n      super.onReaddir(rdResult);\n    }; // maintain the index so that we process them in-order only once all\n    // are completed, otherwise the parallelism messes things up, since a\n    // glob like **/*.js will always be slower than a subsequent !foo.js\n\n\n    patterns.forEach(({\n      pattern,\n      negate\n    }, i) => this.globFiles(pattern, (er, res) => then(pattern, negate, er, res, i)));\n  }\n\n  filterEntry(entry, partial) {\n    // get the partial path from the root of the walk\n    const p = this.path.slice(this.root.length + 1);\n    const {\n      isProject\n    } = this;\n    const pkg = isProject && pathHasPkg(entry) ? pkgFromPath(entry) : null;\n    const rootNM = isProject && entry === 'node_modules';\n    const rootPJ = isProject && entry === 'package.json';\n    return (// if we're in a bundled package, check with the parent.\n      /^node_modules($|\\/)/i.test(p) && !this.isProject ? this.parent.filterEntry(this.basename + '/' + entry, partial) // if package is bundled, all files included\n      // also include @scope dirs for bundled scoped deps\n      // they'll be ignored if no files end up in them.\n      // However, this only matters if we're in the root.\n      // node_modules folders elsewhere, like lib/node_modules,\n      // should be included normally unless ignored.\n      : pkg ? this.bundled.indexOf(pkg) !== -1 || this.bundledScopes.indexOf(pkg) !== -1 // only walk top node_modules if we want to bundle something\n      : rootNM ? !!this.bundled.length // always include package.json at the root.\n      : rootPJ ? true // always include readmes etc in any included dir\n      : packageMustHavesRE.test(entry) ? true // npm-shrinkwrap and package.json always included in the root pkg\n      : isProject && (entry === 'npm-shrinkwrap.json' || entry === 'package.json') ? true // package-lock never included\n      : isProject && entry === 'package-lock.json' ? false // otherwise, follow ignore-walk's logic\n      : super.filterEntry(entry, partial)\n    );\n  }\n\n  filterEntries() {\n    if (this.ignoreRules['.npmignore']) {\n      this.ignoreRules['.gitignore'] = null;\n    }\n\n    this.filterEntries = super.filterEntries;\n    super.filterEntries();\n  }\n\n  addIgnoreFile(file, then) {\n    const ig = path.resolve(this.path, file);\n\n    if (file === 'package.json' && !this.isProject) {\n      then();\n    } else if (this.packageJsonCache.has(ig)) {\n      this.onPackageJson(ig, this.packageJsonCache.get(ig), then);\n    } else {\n      super.addIgnoreFile(file, then);\n    }\n  }\n\n  onPackageJson(ig, pkg, then) {\n    this.packageJsonCache.set(ig, pkg);\n\n    if (Array.isArray(pkg.files)) {\n      // in this case we already included all the must-haves\n      super.onReadIgnoreFile('package.json', pkg.files.map(f => '!' + f).join('\\n') + '\\n', then);\n    } else {\n      // if there's a bin, browser or main, make sure we don't ignore it\n      // also, don't ignore the package.json itself, or any files that\n      // must be included in the package.\n      const rules = this.mustHaveFilesFromPackage(pkg).map(f => `!${f}`);\n      const data = rules.join('\\n') + '\\n';\n      super.onReadIgnoreFile(packageNecessaryRules, data, then);\n    }\n  } // override parent stat function to completely skip any filenames\n  // that will break windows entirely.\n  // XXX(isaacs) Next major version should make this an error instead.\n\n\n  stat({\n    entry,\n    file,\n    dir\n  }, then) {\n    if (nameIsBadForWindows(entry)) {\n      then();\n    } else {\n      super.stat({\n        entry,\n        file,\n        dir\n      }, then);\n    }\n  } // override parent onstat function to nix all symlinks, other than\n  // those coming out of the followed bundled symlink deps\n\n\n  onstat({\n    st,\n    entry,\n    file,\n    dir,\n    isSymbolicLink\n  }, then) {\n    if (st.isSymbolicLink()) {\n      then();\n    } else {\n      super.onstat({\n        st,\n        entry,\n        file,\n        dir,\n        isSymbolicLink\n      }, then);\n    }\n  }\n\n  onReadIgnoreFile(file, data, then) {\n    if (file === 'package.json') {\n      try {\n        const ig = path.resolve(this.path, file);\n        this.onPackageJson(ig, JSON.parse(data), then);\n      } catch (er) {\n        // ignore package.json files that are not json\n        then();\n      }\n    } else {\n      super.onReadIgnoreFile(file, data, then);\n    }\n  }\n\n  sort(a, b) {\n    // optimize for compressibility\n    // extname, then basename, then locale alphabetically\n    // https://twitter.com/isntitvacant/status/1131094910923231232\n    const exta = path.extname(a).toLowerCase();\n    const extb = path.extname(b).toLowerCase();\n    const basea = path.basename(a).toLowerCase();\n    const baseb = path.basename(b).toLowerCase();\n    return exta.localeCompare(extb, 'en') || basea.localeCompare(baseb, 'en') || a.localeCompare(b, 'en');\n  }\n\n  globFiles(pattern, cb) {\n    glob(globify(pattern), {\n      dot: true,\n      cwd: this.path,\n      nocase: true\n    }, cb);\n  }\n\n  readPackageJson(entries) {\n    fs.readFile(this.path + '/package.json', (er, pkg) => this.onReadPackageJson(entries, er, pkg));\n  }\n\n  walker(entry, opt, then) {\n    new Walker(this.walkerOpt(entry, opt)).on('done', then).start();\n  }\n\n}\n\nconst walk = (options, callback) => {\n  options = options || {};\n  const p = new Promise((resolve, reject) => {\n    const bw = new BundleWalker(options);\n    bw.on('done', bundled => {\n      options.bundled = bundled;\n      options.packageJsonCache = bw.packageJsonCache;\n      new Walker(options).on('done', resolve).on('error', reject).start();\n    });\n    bw.start();\n  });\n  return callback ? p.then(res => callback(null, res), callback) : p;\n};\n\nmodule.exports = walk;\nwalk.Walker = Walker;","map":null,"metadata":{},"sourceType":"script"}